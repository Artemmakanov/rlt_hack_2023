{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51214db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to /home/user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from natasha import Doc, MorphVocab, Segmenter, NewsEmbedding, NewsMorphTagger\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words= nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e43d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d8657d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ab6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text_data):\n",
    "    \"\"\"\n",
    "    Функция для лемматизации текста\n",
    "    \"\"\"\n",
    "\n",
    "    doc = Doc(text_data)\n",
    "\n",
    "    doc.segment(segmenter)\n",
    "\n",
    "    doc.tag_morph(morph_tagger)\n",
    "\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "    return [_.lemma for _ in doc.tokens]\n",
    "\n",
    "def delete_stop_words(text_data, stop_words):\n",
    "    \"\"\"\n",
    "    Функция для удаления стоп-слов\n",
    "    \"\"\"\n",
    "    return [word for word in text_data if not word in stop_words]\n",
    "\n",
    "\n",
    "def delete_number_and_signs_words(text_data):\n",
    "    \"\"\"\n",
    "    Функция для удаления ненужных символов\n",
    "    \"\"\"\n",
    "    alphabet = (\"а\",\"б\",\"в\",\"г\",\"д\",\"е\",\"ё\",\"ж\",\"з\",\"и\",\"й\",\"к\",\"л\",\"м\",\"н\",\"о\",\n",
    "            \"п\",\"р\",\"с\",\"т\",\"у\",\"ф\",\"х\",\"ц\",\"ч\",\"ш\",\"щ\",\"ъ\",\"ы\",\"ь\",\"э\",\"ю\",\"я\")\n",
    "    return [word for word in text_data if  \n",
    "                              all(letter in alphabet for letter in word)]\n",
    "\n",
    "def preserve_nouns(text_data):\n",
    "    doc = Doc(\" \".join(text_data))\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    return [token.text for token in doc.tokens if token.pos=='NOUN']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da3d9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "HtmlFile = open('messages.html', 'r', encoding='utf-8')\n",
    "source_code = HtmlFile.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3cc8a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bfd0a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "parsed_html = BeautifulSoup(source_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "93cfd6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = parsed_html.find_all('div', attrs={'class':'text'})[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "db78b201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Добро пожаловать в официальный телеграм-канал оператора электронных торгов «Росэлторг»!Здесь вас ждут:✅ актуальные новости компании: новые продукты, нововведения в уже существующих, анонсы мероприятий✅ новости отрасли: что происходит в мире закупок и как с этим работать✅ лайфхаки для заказчиков и поставщиков: разбираем законодательство, делимся гайдами по закупкам и ответами на ваши вопросы от экспертов✅ интересные закупки, опубликованные на площадке «Росэлторг»Подписывайтесь и следите за миром закупок вместе с нами!\n",
      "       \n"
     ]
    }
   ],
   "source": [
    "texts = [message.text for message in messages]\n",
    "dst_text = texts[0]\n",
    "print(dst_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8754ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8ac894ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in enumerate(texts):\n",
    "    lemmatized_text = lemmatize_text(text)\n",
    "    sw_d_text = delete_stop_words(lemmatized_text, stop_words)\n",
    "    d_nas_text = delete_number_and_signs_words(sw_d_text)\n",
    "    nouns_text = preserve_nouns(d_nas_text)\n",
    "    texts[i] = \" \".join(nouns_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df6e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b0635be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5e1e8d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_tfidf =  X.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5414dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2v = {i: dst_tfidf[i] for i in range(len(dst_tfidf))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "77807007",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2v_sorted = dict(sorted(ind2v.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "71e53057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['мир', 'новость', 'закупка', 'анонс', 'гайда']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 1.6\n",
    "sum_ = 0.\n",
    "i = 0\n",
    "lst = []\n",
    "while sum_ < p and i < len(ind2v_sorted):\n",
    "    sum_ += list(ind2v_sorted.values())[i]\n",
    "    lst.append(list(ind2v_sorted.keys())[i])\n",
    "    i += 1\n",
    "vectorizer.get_feature_names_out()[lst].tolist()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e562c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178fdbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d6a122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e5f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
